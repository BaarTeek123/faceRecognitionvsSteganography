{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Configuration\n",
    "#### Load dependencies"
   ],
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3464974836.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;36m  Cell \u001B[0;32mIn[1], line 1\u001B[0;36m\u001B[0m\n\u001B[0;31m    Load dependencies\u001B[0m\n\u001B[0m         ^\u001B[0m\n\u001B[0;31mSyntaxError\u001B[0m\u001B[0;31m:\u001B[0m invalid syntax\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-20 22:30:20.234749: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-07-20 22:30:20.331740: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-07-20 22:30:20.333426: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-07-20 22:30:21.192060: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "import face_recognition\n",
    "from PIL import Image\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import uuid\n",
    "\n",
    "# import tf dependencies\n",
    "import tensorflow as tf\n",
    "from keras.models import Model\n",
    "from keras.layers import Layer, Conv2D, Dense, MaxPooling2D, Input, Flatten\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Config GPU"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    print(gpu)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Define constants"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "POSITIVE_PATH = os.path.normpath(os.path.join('data', 'positive'))\n",
    "NEGATIVE_PATH = os.path.normpath(os.path.join('data', 'negative'))\n",
    "ANCHOR_PATH = os.path.normpath(os.path.join('data', 'anchor'))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Create directories"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "os.makedirs(POSITIVE_PATH, exist_ok=True)\n",
    "os.makedirs(NEGATIVE_PATH, exist_ok=True)\n",
    "os.makedirs(ANCHOR_PATH, exist_ok=True)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Data collection"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "face_locations = None\n",
    "capture_mode = None\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if face_locations is None:\n",
    "        face_locations = face_recognition.face_locations(frame)\n",
    "        t, r, b, l = face_locations[0]\n",
    "        y_margin = 250 - abs(t-b)\n",
    "        x_margin = 250 - abs(l-r)\n",
    "     # get 250 x 250 image basing on initial face position\n",
    "    frame = frame[t-y_margin//2: b+y_margin//2, l - x_margin//2:r+x_margin//2, :]\n",
    "\n",
    "    key = cv2.waitKey(1) & 0XFF\n",
    "    # Change mode\n",
    "    if key == ord('a'):\n",
    "        capture_mode = 'a'\n",
    "    elif key == ord('p'):\n",
    "        capture_mode = 'p'\n",
    "    elif key == ord('q'):\n",
    "        break\n",
    "\n",
    "    # collect samples based on current mode\n",
    "    if capture_mode == 'a':\n",
    "        cv2.imwrite(os.path.join(ANCHOR_PATH, f'{uuid.uuid1()}.jpg'), frame)\n",
    "    elif capture_mode == 'p':\n",
    "        cv2.imwrite(os.path.join(POSITIVE_PATH, f'{uuid.uuid1()}.jpg'), frame)\n",
    "\n",
    "    cv2.imshow('Image collection', frame)\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Image preprocessing"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "anchor = tf.data.Dataset.list_files(os.path.join(ANCHOR_PATH, '*.jpg'))\n",
    "positive = tf.data.Dataset.list_files(os.path.join(POSITIVE_PATH, '*.jpg'))\n",
    "negative = tf.data.Dataset.list_files(os.path.join(NEGATIVE_PATH, '*.jpg'))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [],
   "source": [
    "def preprocess(path_to_file):\n",
    "    \"\"\"Function that read file from file, resize and rescale numpy array\"\"\"\n",
    "    img = tf.io.decode_jpeg(tf.io.read_file(path_to_file))\n",
    "    return tf.image.resize(img, (100, 100)) / 255\n",
    "\n",
    "def preprocess_twin(input_img, val_img, label):\n",
    "    return preprocess(input_img), preprocess(val_img), label"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [],
   "source": [
    "positives = tf.data.Dataset.zip((anchor, positive, tf.data.Dataset.from_tensor_slices(tf.ones(len(anchor)))))\n",
    "negatives = tf.data.Dataset.zip((anchor, negative, tf.data.Dataset.from_tensor_slices(tf.zeros(len(anchor)))))\n",
    "data = positives.concatenate(negatives)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [
    {
     "data": {
      "text/plain": "<_ShuffleDataset element_spec=(TensorSpec(shape=(100, 100, None), dtype=tf.float32, name=None), TensorSpec(shape=(100, 100, None), dtype=tf.float32, name=None), TensorSpec(shape=(), dtype=tf.float32, name=None))>"
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.map(preprocess_twin)\n",
    "data = data.cache()\n",
    "data.shuffle(buffer_size=1024)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [],
   "source": [
    "TRAIN_RATIO = 0.7\n",
    "TEST_RATIO = 1 - TRAIN_RATIO"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_data = data.skip(round(len(data)*TRAIN_RATIO))\n",
    "test_data = test_data.take(round(len(data)*TEST_RATIO))\n",
    "test_data = test_data.batch(16)\n",
    "test_data = test_data.prefetch(8)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}