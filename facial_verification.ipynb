{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Configuration\n",
    "#### Load dependencies"
   ],
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3464974836.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;36m  Cell \u001B[0;32mIn[1], line 1\u001B[0;36m\u001B[0m\n\u001B[0;31m    Load dependencies\u001B[0m\n\u001B[0m         ^\u001B[0m\n\u001B[0;31mSyntaxError\u001B[0m\u001B[0;31m:\u001B[0m invalid syntax\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import face_recognition\n",
    "from PIL import Image\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import uuid\n",
    "\n",
    "# import tf dependencies\n",
    "import tensorflow as tf\n",
    "from keras.models import Model\n",
    "from keras.layers import Layer, Input, Conv2D, MaxPooling2D, GlobalAveragePooling2D, Flatten, BatchNormalization, Dropout, Dense, LeakyReLU\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.metrics import classification_report\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Config GPU"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    print(gpu)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Define constants"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "POSITIVE_PATH = os.path.normpath(os.path.join('data', 'positive'))\n",
    "NEGATIVE_PATH = os.path.normpath(os.path.join('data', 'negative'))\n",
    "ANCHOR_PATH = os.path.normpath(os.path.join('data', 'anchor'))\n",
    "PIXELS_SIZE = 100"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Create directories"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "os.makedirs(POSITIVE_PATH, exist_ok=True)\n",
    "os.makedirs(NEGATIVE_PATH, exist_ok=True)\n",
    "os.makedirs(ANCHOR_PATH, exist_ok=True)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Data collection"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "face_locations = None\n",
    "capture_mode = None\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if face_locations is None:\n",
    "        face_locations = face_recognition.face_locations(frame)\n",
    "        t, r, b, l = face_locations[0]\n",
    "        y_margin = 250 - abs(t-b)\n",
    "        x_margin = 250 - abs(l-r)\n",
    "     # get 250 x 250 image basing on initial face position\n",
    "    frame = frame[t-y_margin//2: b+y_margin//2, l - x_margin//2:r+x_margin//2, :]\n",
    "\n",
    "    key = cv2.waitKey(1) & 0XFF\n",
    "    # Change mode\n",
    "    if key == ord('a'):\n",
    "        capture_mode = 'a'\n",
    "    elif key == ord('p'):\n",
    "        capture_mode = 'p'\n",
    "    elif key == ord('q'):\n",
    "        break\n",
    "\n",
    "    # collect samples based on current mode\n",
    "    if capture_mode == 'a':\n",
    "        cv2.imwrite(os.path.join(ANCHOR_PATH, f'{uuid.uuid1()}.jpg'), frame)\n",
    "    elif capture_mode == 'p':\n",
    "        cv2.imwrite(os.path.join(POSITIVE_PATH, f'{uuid.uuid1()}.jpg'), frame)\n",
    "\n",
    "    cv2.imshow('Image collection', frame)\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Image preprocessing"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "anchor = tf.data.Dataset.list_files(os.path.join(ANCHOR_PATH, '*.jpg'))\n",
    "positive = tf.data.Dataset.list_files(os.path.join(POSITIVE_PATH, '*.jpg'))\n",
    "negative = tf.data.Dataset.list_files(os.path.join(NEGATIVE_PATH, '*.jpg'))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Define functions"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "def preprocess(path_to_file):\n",
    "    \"\"\"Function that read file from file, resize and rescale numpy array\"\"\"\n",
    "    img = tf.io.decode_jpeg(tf.io.read_file(path_to_file))\n",
    "    return tf.image.resize(img, (PIXELS_SIZE, PIXELS_SIZE)) / 255\n",
    "\n",
    "def preprocess_twin(input_img, val_img, label):\n",
    "    return preprocess(input_img), preprocess(val_img), label"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Define dataset"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "positives = tf.data.Dataset.zip((anchor, positive, tf.data.Dataset.from_tensor_slices(tf.ones(len(anchor)))))\n",
    "negatives = tf.data.Dataset.zip((anchor, negative, tf.data.Dataset.from_tensor_slices(tf.zeros(len(anchor)))))\n",
    "data = positives.concatenate(negatives)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "<_ShuffleDataset element_spec=(TensorSpec(shape=(100, 100, None), dtype=tf.float32, name=None), TensorSpec(shape=(100, 100, None), dtype=tf.float32, name=None), TensorSpec(shape=(), dtype=tf.float32, name=None))>"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.map(preprocess_twin)\n",
    "data = data.cache()\n",
    "data.shuffle(buffer_size=1024)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "TRAIN_RATIO = 0.7\n",
    "TEST_RATIO = 1 - TRAIN_RATIO"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "#### Split dataset"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "train_data = data.take(round(len(data)*.7))\n",
    "train_data = train_data.batch(16)\n",
    "train_data = train_data.prefetch(8)\n",
    "\n",
    "test_data = data.skip(round(len(data)*TRAIN_RATIO))\n",
    "test_data = test_data.take(round(len(data)*TEST_RATIO))\n",
    "test_data = test_data.batch(16)\n",
    "test_data = test_data.prefetch(8)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Define the model\n",
    "#### Create embedding layers"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "def make_embedding():\n",
    "    inp = Input(shape=(PIXELS_SIZE,PIXELS_SIZE,3), name='input_image')\n",
    "    leaky_relu = LeakyReLU()\n",
    "\n",
    "    # First block\n",
    "    c1 = Conv2D(64, (10,10))(inp)\n",
    "    c1 = leaky_relu(c1)\n",
    "    c1 = BatchNormalization()(c1)\n",
    "    m1 = MaxPooling2D((2,2), padding='same')(c1)\n",
    "\n",
    "    # Second block\n",
    "    c2 = Conv2D(128, (7,7))(m1)\n",
    "    c2 = leaky_relu(c2)\n",
    "    c2 = BatchNormalization()(c2)\n",
    "    m2 = MaxPooling2D((2,2), padding='same')(c2)\n",
    "\n",
    "    # Third block\n",
    "    c3 = Conv2D(128, (4,4))(m2)\n",
    "    c3 = leaky_relu(c3)\n",
    "    c3 = BatchNormalization()(c3)\n",
    "    m3 = MaxPooling2D((2,2), padding='same')(c3)\n",
    "\n",
    "    # Final embedding block\n",
    "    c4 = Conv2D(256, (4,4))(m3)\n",
    "    c4 = leaky_relu(c4)\n",
    "    c4 = BatchNormalization()(c4)\n",
    "\n",
    "\n",
    "    f1 = Flatten()(c4)\n",
    "    d1 = Dense(1024, activation='relu')(f1)\n",
    "    d1 = Dropout(0.5)(d1)\n",
    "    d2 = Dense(4096, activation='sigmoid')(d1)\n",
    "\n",
    "    return Model(inputs=[inp], outputs=[d2], name='embedding')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"embedding\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_image (InputLayer)       [(None, 100, 100, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 91, 91, 64)   19264       ['input_image[0][0]']            \n",
      "                                                                                                  \n",
      " leaky_re_lu (LeakyReLU)        multiple             0           ['conv2d[0][0]',                 \n",
      "                                                                  'conv2d_1[0][0]',               \n",
      "                                                                  'conv2d_2[0][0]',               \n",
      "                                                                  'conv2d_3[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 91, 91, 64)  256         ['leaky_re_lu[0][0]']            \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " max_pooling2d (MaxPooling2D)   (None, 46, 46, 64)   0           ['batch_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, 40, 40, 128)  401536      ['max_pooling2d[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 40, 40, 128)  512        ['leaky_re_lu[1][0]']            \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling2d_1 (MaxPooling2D)  (None, 20, 20, 128)  0          ['batch_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)              (None, 17, 17, 128)  262272      ['max_pooling2d_1[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 17, 17, 128)  512        ['leaky_re_lu[2][0]']            \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling2d_2 (MaxPooling2D)  (None, 9, 9, 128)   0           ['batch_normalization_2[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)              (None, 6, 6, 256)    524544      ['max_pooling2d_2[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 6, 6, 256)   1024        ['leaky_re_lu[3][0]']            \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 9216)         0           ['batch_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 1024)         9438208     ['flatten[0][0]']                \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 1024)         0           ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 4096)         4198400     ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 14,846,528\n",
      "Trainable params: 14,845,376\n",
      "Non-trainable params: 1,152\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "embedding = make_embedding()\n",
    "embedding.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### A distance layer - Siamese Distance class"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "class L1Dist(Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__()\n",
    "\n",
    "    def call(self, input_emb, val_emb):\n",
    "        return tf.math.abs(input_emb-val_emb)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Create Siamese model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "def make_siamese_model(num_classes=None):\n",
    "    \"\"\"\n",
    "    Create a siamese network model.\n",
    "    This network will have two inputs (anchor, validation),\n",
    "    each one goes through the same embedding model and the output embeddings are compared.\n",
    "    \"\"\"\n",
    "    # Anchor image input in the network\n",
    "    input_img = Input(shape=(PIXELS_SIZE,PIXELS_SIZE,3), name='anchor_input')\n",
    "\n",
    "    # Validation image in the network\n",
    "    val_img = Input(shape=(PIXELS_SIZE,PIXELS_SIZE,3), name='validation_input')\n",
    "    # Combine siamese distance components\n",
    "    siam_layer =  L1Dist(name='distance')\n",
    "    distances =siam_layer(embedding(input_img), embedding(val_img))\n",
    "\n",
    "    if num_classes == None:\n",
    "        classifier = Dense(1, activation='sigmoid')(distances)\n",
    "    else:\n",
    "        output = Dense(num_classes, activation='softmax')(distances)\n",
    "\n",
    "\n",
    "    return Model(inputs=[input_img, val_img], outputs=classifier, name='SiameseNetwork')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "siamese_model = make_siamese_model()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Training"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "bce_loss = tf.losses.BinaryCrossentropy()\n",
    "opt = Adam(0.0001)\n",
    "checkpt_pref = os.path.normpath(os.path.join('checkpoint', 'checkpt'))\n",
    "checkpt = tf.train.Checkpoint(opt=opt, siamese_model=siamese_model)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(batch):\n",
    "    with tf.GradientTape() as tape:\n",
    "        # get anchor & pos/neg image and label\n",
    "        X = batch[:2]\n",
    "        y = batch[2]\n",
    "\n",
    "        y_pred= siamese_model(X, training=True) #\n",
    "        loss = bce_loss(y, y_pred) # get loss\n",
    "    # get gradients\n",
    "    grad = tape.gradient(loss, siamese_model.trainable_variables)\n",
    "    # update weights\n",
    "    opt.apply_gradients(zip(grad, siamese_model.trainable_variables))\n",
    "\n",
    "    return loss"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Train step function"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "def train(train_data, EPOCHS=50):\n",
    "    for epoch in range(EPOCHS):\n",
    "        print(f'Epoch {epoch+1}')\n",
    "        progbar = tf.keras.utils.Progbar(len(train_data))\n",
    "\n",
    "        for idx, batch in enumerate(train_data):\n",
    "            train_step(batch)\n",
    "            progbar.update(idx+1)\n",
    "\n",
    "        if not epoch % 10:\n",
    "            checkpt.save(file_prefix=checkpt_pref)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Train"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "train(train_data=train_data)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_inp, test_val, y_true = test_data.as_numpy_iterator().next()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% \n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "#### Save model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md \n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "siamese_model.save(os.path.join('models', 'siamesemodel.h5'))\n",
    "siamese_model = tf.keras.models.load_model('siamesemodelv2.h5', \n",
    "                                   custom_objects={'L1Dist':L1Dist, 'BinaryCrossentropy':tf.losses.BinaryCrossentropy})"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% \n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% \n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}